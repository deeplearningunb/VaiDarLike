{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: lime==0.1.1.36 in /Users/lucasfellipe/Desktop/VaiDarLike/venv/lib/python2.7/site-packages (from -r ../requirements.txt (line 1)) (0.1.1.36)\n",
      "Requirement already satisfied: seaborn==0.9.0 in /Users/lucasfellipe/Desktop/VaiDarLike/venv/lib/python2.7/site-packages (from -r ../requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: tqdm==4.39.0 in /Users/lucasfellipe/Desktop/VaiDarLike/venv/lib/python2.7/site-packages (from -r ../requirements.txt (line 3)) (4.39.0)\n",
      "Requirement already satisfied: spacy==2.2.3 in /Users/lucasfellipe/Desktop/VaiDarLike/venv/lib/python2.7/site-packages (from -r ../requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: Keras==2.3.1 in /Users/lucasfellipe/Desktop/VaiDarLike/venv/lib/python2.7/site-packages (from -r ../requirements.txt (line 5)) (2.3.1)\n",
      "Collecting pyLDAvis==2.1.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 870kB/s eta 0:00:01\n",
      "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement pylab==0.0.1 (from -r ../requirements.txt (line 7)) (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pylab==0.0.1 (from -r ../requirements.txt (line 7))\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/lm/vocabulary.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Counter, Iterable\n",
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/google/protobuf/descriptor.py:47: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from google.protobuf.pyext import _message\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/util.py:448: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class _ObjectIdentitySet(collections.MutableSet):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import random\n",
    "import operator\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from statistics import *\n",
    "import concurrent.futures\n",
    "import time\n",
    "import pyLDAvis.sklearn\n",
    "from pylab import bone, pcolor, colorbar, plot, show, rcParams, savefig\n",
    "import warnings\n",
    "import nltk\n",
    "\n",
    "\n",
    "# spaCy based imports\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# keras module for building LSTM \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as ku \n",
    "\n",
    "# set seeds for reproducability\n",
    "from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "set_random_seed(2)\n",
    "seed(1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "british_yt = pd.read_csv(\"../dataset/GBvideos.csv\")\n",
    "canadian_yt = pd.read_csv(\"../dataset/CAvideos.csv\")\n",
    "us_yt = pd.read_csv(\"../dataset/USvideos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_countries=pd.concat([canadian_yt, british_yt,us_yt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_countries=three_countries.drop_duplicates(['video_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def category_name(path):\n",
    "    with open(path) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "    category_info_list=[]\n",
    "    for row in data['items']:\n",
    "        id_info=row['id']\n",
    "        category_name=row['snippet']['title']\n",
    "        categoty_info=(id_info ,category_name)\n",
    "        category_info_list.append(categoty_info)\n",
    "    return(dict(category_info_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Film & Animation',\n",
       " '2': 'Autos & Vehicles',\n",
       " '10': 'Music',\n",
       " '15': 'Pets & Animals',\n",
       " '17': 'Sports',\n",
       " '18': 'Short Movies',\n",
       " '19': 'Travel & Events',\n",
       " '20': 'Gaming',\n",
       " '21': 'Videoblogging',\n",
       " '22': 'People & Blogs',\n",
       " '23': 'Comedy',\n",
       " '24': 'Entertainment',\n",
       " '25': 'News & Politics',\n",
       " '26': 'Howto & Style',\n",
       " '27': 'Education',\n",
       " '28': 'Science & Technology',\n",
       " '30': 'Movies',\n",
       " '31': 'Anime/Animation',\n",
       " '32': 'Action/Adventure',\n",
       " '33': 'Classics',\n",
       " '34': 'Comedy',\n",
       " '35': 'Documentary',\n",
       " '36': 'Drama',\n",
       " '37': 'Family',\n",
       " '38': 'Foreign',\n",
       " '39': 'Horror',\n",
       " '40': 'Sci-Fi/Fantasy',\n",
       " '41': 'Thriller',\n",
       " '42': 'Shorts',\n",
       " '43': 'Shows',\n",
       " '44': 'Trailers'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_name(\"../dataset/CA_category_id.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
